{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial example using FGSM(Needs Dataset on local machine)\n",
    "\n",
    "<b>We have used FGSM generation example code from the below example and modified it our needs for making a Techincal Report.</b><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb\">View source on GitHub</a>\n",
    "</br>\n",
    "</br>\n",
    "<b>The stored excel files for differnet models and different datasets are used for creation of graphs represented in Techincal review</b></br></br>\n",
    "<b>The dataset consists of 1500 images downloaded from imageCV</b> <a target=\"_blank\" href=\"https://images.cv\">imagenet</a></br></br>\n",
    "<b>All the models are trained as using imagenet</b> <a target=\"_blank\" href=\"https://image-net.org/\">imagenet</a></br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import xlwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to preprocess the image so that it can be inputted into neural network or model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to preprocess the image so that it can be inputted into neural network or model\n",
    "def preprocess(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = tf.image.resize(image, (224, 224))\n",
    "  image = tf.keras.applications.densenet.preprocess_input(image)\n",
    "  image = image[None, ...]\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to extract labels from probability vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract labels from probability vector\n",
    "def get_imagenet_label(probs):\n",
    "  #print(decode_predictions(probs, top=1)[0][0])\n",
    "  return decode_predictions(probs, top=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(image, description):\n",
    "  _, label, confidence = get_imagenet_label(pretrained_model.predict(image))\n",
    "  #Commenting out the code image plotting code as this code is created or modified to manage huge amout of datasets.\n",
    "  #plt.figure()\n",
    "  #plt.imshow(image[0]*0.5+0.5)\n",
    "  #plt.title('{} \\n {} : {:.2f}% Confidence'.format(description,label, confidence*100))\n",
    "\n",
    "  return label,confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(input_image):\n",
    "    #calculating the prediction probabilities across all the labels of imagenet\n",
    "    label_probalities = pretrained_model(input_image)\n",
    "    #extracting the array of predictions from tensorflow object using numpy method of tensorflow\n",
    "    label_array=label_probalities.numpy()[0]\n",
    "    #returing the index where the prediction value is higher than all the others\n",
    "    return label_array.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def create_adversarial_pattern(input_image, input_label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = pretrained_model(input_image)\n",
    "    \n",
    "    #calculating Crossentropyloss using CategoricalCrossentropy\n",
    "    \n",
    "    loss = loss_object(input_label, prediction)\n",
    "    print(loss.numpy())\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  # sign function outputs -1 if x < 0, 0 if x==0, 1 if x > 0\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiating new workbook and writing the coloumn names\n",
    "Workbook=xlwt.Workbook()\n",
    "Worksheet=Workbook.add_sheet(\"sheet_name\")\n",
    "Worksheet.write(0,0,\"Image_name\")\n",
    "Worksheet.write(0,1,\"Epsilon 0\")\n",
    "Worksheet.write(0,2,\"Epsilon 0.01\")\n",
    "Worksheet.write(0,3,\"Epsilon 0.1\")\n",
    "Worksheet.write(0,4,\"Epsilon 0.15\")\n",
    "\n",
    "#initiating the model in this case ResNet152V2 , we have tested this with densenet and mobilenetV2 also \n",
    "# model wieghts or pre-trained on imagenet\n",
    "pretrained_model = tf.keras.applications.ResNet152V2(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "\n",
    "#making the model non trainable as our aim is to fool the trained model\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8391348\n",
      "1.6290054\n",
      "0.039658215\n",
      "1.0032259\n",
      "0.9822746\n",
      "1.265406\n",
      "0.037520386\n",
      "0.5068579\n",
      "0.5347562\n",
      "2.154755\n",
      "1.3662841\n",
      "1.5268553\n",
      "1.078107\n",
      "1.9457966\n",
      "1.4153956\n",
      "0.90997565\n",
      "1.8964714\n",
      "0.10196557\n",
      "0.33840504\n",
      "1.2447226\n",
      "0.39296958\n",
      "0.18539178\n",
      "1.8254468\n",
      "0.14096335\n",
      "0.81097025\n",
      "0.18039332\n",
      "1.1759006\n",
      "0.06857697\n",
      "0.13935249\n",
      "0.18252741\n",
      "0.9679614\n",
      "0.46756902\n",
      "0.024764229\n",
      "0.1380076\n",
      "0.029584816\n",
      "1.8100718\n",
      "0.7873336\n",
      "0.2016861\n",
      "0.16657792\n",
      "0.8945836\n",
      "1.3790927\n",
      "0.012352276\n",
      "1.8386296\n",
      "0.21769834\n",
      "1.1256003\n",
      "1.6576155\n",
      "0.798827\n",
      "2.2557387\n",
      "1.2775688\n",
      "0.27406603\n",
      "1.4574662\n",
      "0.9892485\n",
      "0.005343678\n",
      "1.3257617\n",
      "1.5505307\n",
      "0.7492521\n",
      "1.0562913\n",
      "0.72136843\n",
      "0.2651161\n",
      "1.0251391\n",
      "0.74972475\n",
      "1.5810742\n",
      "0.94107544\n",
      "0.32034644\n",
      "0.63972557\n",
      "0.33476207\n",
      "2.064329\n",
      "0.33549687\n",
      "2.0338442\n",
      "1.3286324\n",
      "1.4152932\n",
      "0.6639339\n",
      "0.3047828\n",
      "1.3860083\n",
      "0.04892544\n",
      "1.4081632\n",
      "0.7813827\n",
      "0.6189529\n",
      "1.630581\n",
      "0.090497434\n",
      "0.48989213\n",
      "2.6324284\n",
      "0.051381435\n",
      "0.004594247\n",
      "1.4712037\n",
      "1.3112352\n",
      "2.201413\n",
      "0.8119795\n",
      "0.6398325\n",
      "1.4949344\n",
      "0.0026062115\n",
      "0.48907515\n",
      "0.0039746347\n",
      "0.6164445\n",
      "1.5873662\n",
      "0.58511895\n",
      "0.27544606\n",
      "1.6689287e-06\n",
      "0.11923168\n",
      "0.0051271385\n",
      "0.093395606\n",
      "2.0667226\n",
      "2.0485644\n",
      "1.2545319\n",
      "0.28460464\n",
      "0.016089952\n",
      "0.3587817\n",
      "1.8911554\n",
      "0.9900967\n",
      "0.4090197\n",
      "0.41775322\n",
      "0.9602061\n",
      "0.58703005\n",
      "0.00026294112\n",
      "0.8980747\n",
      "1.0639905\n",
      "1.732767\n",
      "1.8864704\n",
      "0.822833\n",
      "0.68265265\n",
      "1.5717876\n",
      "0.78821915\n",
      "0.0042373636\n",
      "0.6633814\n",
      "0.16422914\n",
      "0.0013537776\n",
      "0.3340227\n",
      "0.019362371\n",
      "1.541183\n",
      "1.5854658\n",
      "1.4913223\n",
      "1.7419008\n",
      "1.2779716\n",
      "1.9063907\n",
      "0.44632372\n",
      "0.1318935\n",
      "0.7845722\n",
      "0.8261245\n",
      "1.2344294\n",
      "0.7778022\n",
      "0.7760235\n",
      "1.7575392\n",
      "0.2751255\n",
      "2.1961417\n",
      "0.6441812\n",
      "0.036692884\n",
      "1.296528\n",
      "0.092206165\n",
      "0.71066886\n",
      "1.3576268\n",
      "0.89674616\n",
      "1.193094\n",
      "0.47804135\n",
      "0.4619594\n",
      "2.4185317\n",
      "0.06801325\n",
      "1.3137769\n",
      "1.6705186\n",
      "2.681168\n",
      "0.10395636\n",
      "0.95730585\n",
      "0.022970539\n",
      "0.31546262\n",
      "0.2757074\n",
      "2.4202735\n",
      "0.7755139\n",
      "1.0389022\n",
      "0.99306273\n",
      "1.2502302\n",
      "0.028814076\n",
      "0.022813132\n",
      "1.2315505\n",
      "1.8963516\n",
      "0.089477435\n",
      "0.90426344\n",
      "1.0658319\n",
      "0.100322396\n",
      "4.6371337e-05\n",
      "1.1920676\n",
      "4.804019e-05\n",
      "0.01248732\n",
      "1.5967134\n",
      "1.2604133\n",
      "1.7389629\n",
      "0.5835886\n",
      "2.5391705\n",
      "0.5394882\n",
      "2.8753238\n",
      "0.081855536\n",
      "0.30315992\n",
      "0.28880897\n",
      "2.730072\n",
      "0.438726\n",
      "0.03207428\n",
      "0.0005042474\n",
      "0.6961583\n",
      "1.1034039\n",
      "0.08649932\n",
      "0.46134242\n",
      "0.78407323\n",
      "0.439026\n",
      "1.3362856\n",
      "1.1371987\n",
      "1.5761058\n",
      "0.0227995\n",
      "1.2191355\n",
      "0.038770217\n",
      "0.55419147\n",
      "0.4408456\n",
      "0.016956825\n",
      "0.90579104\n",
      "1.5272115\n",
      "0.021793174\n",
      "0.43332025\n",
      "2.3209171\n",
      "0.015711566\n",
      "0.6681394\n",
      "0.4860003\n",
      "0.91977215\n",
      "0.79877317\n",
      "0.40505692\n",
      "0.72992843\n",
      "0.16549873\n",
      "0.32355207\n",
      "0.42523482\n",
      "0.80936754\n",
      "0.12582716\n",
      "0.36511177\n",
      "0.16947198\n",
      "0.04787156\n",
      "0.58094853\n",
      "0.00013136001\n",
      "0.5943642\n",
      "2.2420928\n",
      "1.4448876\n",
      "1.0280527\n",
      "0.814155\n",
      "0.1288216\n",
      "0.90735525\n",
      "0.059517186\n",
      "0.19406904\n",
      "1.6823052\n",
      "0.836616\n",
      "0.2816223\n",
      "0.9053948\n",
      "1.1471024\n",
      "0.41892645\n",
      "1.1192838\n",
      "0.5221242\n",
      "2.0469234\n",
      "0.10939098\n",
      "1.9266405\n",
      "0.117225826\n",
      "0.4150686\n",
      "0.36189142\n",
      "1.4216636\n",
      "0.120900184\n",
      "2.1032925\n",
      "0.58519\n",
      "0.37987393\n",
      "0.20092414\n",
      "1.1942127\n",
      "0.3873092\n",
      "0.87220246\n",
      "0.12106866\n",
      "2.2349212\n",
      "0.09229748\n",
      "0.21465011\n",
      "1.5005574\n",
      "0.5009496\n",
      "1.3665136\n",
      "1.4050659\n",
      "1.9142383\n",
      "1.335196\n",
      "0.93108255\n",
      "0.7976388\n",
      "1.7187034\n",
      "1.078799\n",
      "0.003981284\n",
      "0.9137063\n",
      "1.2375005\n",
      "1.9493132\n",
      "0.5225792\n",
      "2.0057392\n",
      "0.5754954\n",
      "0.031959634\n",
      "2.2974272\n",
      "1.7434299\n",
      "0.36555865\n",
      "0.81534237\n",
      "0.37648124\n",
      "0.569932\n",
      "1.3501545\n",
      "2.1104045\n",
      "0.5136978\n",
      "1.6838288\n",
      "0.28007016\n",
      "0.32560122\n",
      "0.2234136\n",
      "1.6209428\n",
      "0.22143483\n",
      "0.0018417554\n",
      "0.34665796\n",
      "0.9808957\n",
      "1.3812397\n",
      "1.649889\n",
      "0.35598296\n",
      "1.0839866\n",
      "0.077677295\n",
      "0.7788425\n",
      "0.10250218\n",
      "0.04352209\n",
      "1.4568968\n",
      "0.93993145\n",
      "0.77355254\n",
      "1.7416677\n",
      "0.22279178\n",
      "0.12317254\n",
      "0.3470225\n",
      "1.2628512\n",
      "0.34768757\n",
      "0.6444407\n",
      "1.2347194\n",
      "0.05638515\n",
      "0.6974238\n",
      "0.96453\n",
      "0.13721237\n",
      "1.2464657\n",
      "0.98247266\n",
      "1.3488473\n",
      "0.23314907\n",
      "0.26877025\n",
      "0.22426368\n",
      "0.86008024\n",
      "0.32467836\n",
      "1.1247554\n",
      "1.0531033\n",
      "0.17143206\n",
      "1.875979\n",
      "1.1382403\n",
      "0.49525687\n",
      "0.62726057\n",
      "0.005553532\n",
      "0.22384045\n",
      "1.2343587\n",
      "1.8391573\n",
      "2.3435137\n",
      "1.2620903\n",
      "1.3652024\n",
      "5.3523538e-05\n",
      "1.3815837\n",
      "1.068223\n",
      "0.12081536\n",
      "0.72100586\n",
      "0.81116796\n",
      "1.0719776\n",
      "1.6380401\n",
      "0.51841867\n",
      "0.7057845\n",
      "0.5637061\n",
      "2.0467446\n",
      "1.206146\n",
      "1.7301383\n",
      "1.1722267\n",
      "0.8972078\n",
      "0.024490321\n",
      "0.026723132\n",
      "0.8870683\n",
      "1.4484545\n",
      "2.5049503\n",
      "1.2149321\n",
      "2.0796542\n",
      "1.8741375\n",
      "1.5814458\n",
      "0.00023231193\n",
      "0.9772096\n",
      "0.8956045\n",
      "0.10912369\n",
      "2.0683188\n",
      "1.1873865\n",
      "1.6243237\n",
      "2.3280854\n",
      "1.1849041\n",
      "0.9724877\n",
      "0.9857768\n",
      "0.012105567\n",
      "1.479893\n",
      "1.3186933\n",
      "0.012205318\n",
      "0.13381657\n",
      "0.38367137\n",
      "1.6158662\n",
      "0.83502084\n",
      "1.6034337\n",
      "0.43385625\n",
      "1.3072127\n",
      "0.81068563\n",
      "1.3710973\n",
      "1.8252312\n",
      "0.7582628\n",
      "1.4993101\n",
      "0.24053635\n",
      "1.4721094\n",
      "1.9123703\n",
      "0.58519\n",
      "1.6826694\n",
      "1.2662481\n",
      "1.2210314\n",
      "2.374095\n",
      "0.60672075\n",
      "0.23204187\n",
      "0.03380713\n",
      "0.24944244\n",
      "0.6707367\n",
      "0.8165167\n",
      "0.031567805\n",
      "0.13038756\n",
      "0.51925325\n",
      "0.18445744\n",
      "0.9735923\n",
      "0.049732223\n",
      "1.3161942\n",
      "0.88226897\n",
      "0.03393401\n",
      "1.8668678\n",
      "1.8100141\n",
      "1.0937088\n",
      "1.296964\n",
      "0.12100697\n",
      "2.8739982\n",
      "1.5400691\n",
      "0.52054304\n",
      "0.084757365\n",
      "0.0085372245\n",
      "0.8300055\n",
      "0.032142393\n",
      "0.005196635\n",
      "1.1459178\n",
      "1.6065768\n",
      "1.001632\n",
      "1.2055501\n",
      "0.44800377\n",
      "0.466691\n",
      "0.7712278\n",
      "0.80743825\n",
      "0.0041610333\n",
      "1.4607075\n",
      "0.33858475\n",
      "0.00877158\n",
      "0.53614074\n",
      "0.3007237\n",
      "0.8081546\n",
      "0.0067633046\n",
      "2.5567353\n",
      "0.15170895\n",
      "0.6817802\n",
      "1.8415676\n",
      "1.1717358\n",
      "1.776052\n",
      "0.07718347\n",
      "0.3958623\n",
      "0.038494498\n",
      "1.6398538\n",
      "1.3503859\n",
      "1.8621688\n",
      "2.5042849\n",
      "0.51717764\n",
      "2.1818304\n",
      "1.9319258\n",
      "1.1731712\n",
      "0.82215685\n",
      "0.80454814\n",
      "0.4688964\n",
      "0.056419063\n",
      "0.029098034\n",
      "1.5104513\n",
      "0.58044314\n",
      "0.56586254\n",
      "0.011961165\n",
      "0.32262594\n",
      "0.056497253\n",
      "1.8888025\n",
      "0.004672917\n",
      "0.29015553\n",
      "0.6461245\n",
      "0.4840557\n",
      "1.0039709\n",
      "1.349049\n",
      "0.61588585\n",
      "1.4421297\n",
      "0.06974235\n",
      "0.90110046\n",
      "0.0843458\n",
      "1.6959195\n",
      "0.96134806\n",
      "0.0049869437\n",
      "2.2637625\n",
      "0.54564553\n",
      "0.0056986255\n",
      "1.753503\n",
      "1.2573607\n",
      "0.613029\n",
      "1.2113026\n",
      "0.10840624\n",
      "1.2257578\n",
      "0.012690502\n",
      "0.01947929\n",
      "1.6410483\n",
      "0.48226845\n",
      "0.19194864\n",
      "0.3703759\n",
      "0.22750224\n",
      "0.52669936\n",
      "1.3409567\n",
      "0.6637944\n",
      "0.07514878\n",
      "0.2824111\n",
      "0.043060545\n",
      "0.3907514\n",
      "0.80556\n",
      "1.8596476e-05\n",
      "2.8548436\n",
      "0.0023396043\n",
      "1.726587\n",
      "0.8968926\n",
      "1.8850108\n",
      "0.7192104\n",
      "1.5917021\n",
      "0.5961378\n",
      "1.5917946\n",
      "0.107446216\n",
      "0.1469234\n",
      "1.9327815\n",
      "0.44308755\n",
      "2.129666\n",
      "1.2652556\n",
      "1.1909583\n",
      "0.50843173\n",
      "0.034476947\n",
      "0.20348878\n",
      "0.09213028\n",
      "0.87416667\n",
      "0.4588753\n",
      "2.3512452\n",
      "1.9317317\n",
      "0.5122412\n",
      "0.4340034\n",
      "0.4686244\n",
      "1.6851718\n",
      "0.12125716\n",
      "0.51240516\n",
      "1.1331067\n",
      "0.12820916\n",
      "0.11608395\n",
      "1.0613089\n",
      "0.103107765\n",
      "1.180431\n",
      "1.8326875\n",
      "0.57644457\n",
      "2.1297345\n",
      "0.8160728\n",
      "0.62461275\n",
      "0.0034446924\n",
      "0.718067\n",
      "0.8586363\n",
      "0.0029788904\n",
      "2.4189327\n",
      "0.16061443\n",
      "1.4601732\n",
      "0.62626857\n",
      "1.4175999\n",
      "1.2586856\n",
      "1.7434458\n",
      "0.8370265\n",
      "0.0022349397\n",
      "0.7812251\n",
      "0.49649882\n",
      "3.4469883\n",
      "0.19115739\n",
      "1.5381249\n",
      "1.6063596\n",
      "1.0329418\n",
      "1.8657357\n",
      "0.011281746\n",
      "1.3414723\n",
      "0.7427089\n",
      "0.015492801\n",
      "1.1304832\n",
      "1.6297802\n",
      "0.7733747\n",
      "0.26461548\n",
      "2.0186489\n",
      "1.8221121\n",
      "0.8348507\n",
      "0.38574764\n",
      "1.2502552\n",
      "0.09377404\n",
      "0.72420514\n",
      "0.64194137\n",
      "1.573404\n",
      "1.7052903\n",
      "0.7725047\n",
      "0.23035766\n",
      "0.733073\n",
      "1.6969701\n",
      "0.44153047\n",
      "1.4754101\n",
      "0.16504855\n",
      "0.9492112\n",
      "2.0851846\n",
      "0.37091884\n",
      "0.007997751\n",
      "1.6828172\n",
      "1.1221375\n",
      "1.7660525\n",
      "1.3126693\n",
      "0.3007576\n",
      "1.466156\n",
      "3.0897093\n",
      "0.042313155\n",
      "0.6985864\n",
      "0.003529274\n",
      "0.69428104\n",
      "1.9058704\n",
      "2.0215912\n",
      "0.816309\n",
      "1.8361343\n",
      "0.32836446\n",
      "1.3421264\n",
      "0.22060509\n",
      "0.093048304\n",
      "1.9087123\n",
      "2.5906382\n",
      "0.8671148\n",
      "0.0014835316\n",
      "0.8555019\n",
      "0.8164193\n",
      "0.0076037506\n",
      "0.24385184\n",
      "1.26062\n",
      "0.0002101439\n",
      "0.80957633\n",
      "0.82412493\n",
      "0.9506319\n",
      "1.3569435\n",
      "0.38217998\n",
      "0.4243852\n",
      "1.0737033\n",
      "0.3052922\n",
      "0.1724533\n",
      "0.7894421\n",
      "1.8152969\n",
      "1.3149089\n",
      "1.0845916\n",
      "1.2662994\n",
      "0.9939219\n",
      "0.2901467\n",
      "1.0188473\n",
      "0.5626358\n",
      "0.15438981\n",
      "0.56400436\n",
      "0.8401391\n",
      "1.931986\n",
      "2.4586165\n",
      "1.7485205\n",
      "0.5698311\n",
      "1.0064018\n",
      "0.6527714\n",
      "2.5720131\n",
      "0.033808857\n",
      "0.6265727\n",
      "0.050302252\n",
      "2.094953\n",
      "0.8271913\n",
      "1.41743\n",
      "1.1938126\n",
      "0.81371236\n",
      "1.5117111\n",
      "0.49432248\n",
      "0.340022\n",
      "2.7101889\n",
      "0.7943417\n",
      "2.8054147\n",
      "0.00064388046\n",
      "1.6195714\n",
      "0.03433678\n",
      "1.1997409\n",
      "0.06252456\n",
      "0.7084364\n",
      "0.884512\n",
      "1.4765868\n",
      "1.2670827\n",
      "1.7316269\n",
      "0.5237515\n",
      "2.0847676\n",
      "0.06797572\n",
      "0.7178322\n",
      "0.90135884\n",
      "0.085109524\n",
      "0.24097225\n",
      "0.0015216212\n",
      "0.66418916\n",
      "1.9093924\n",
      "1.2050548\n",
      "0.2034887\n",
      "2.0018392\n",
      "0.114185885\n",
      "0.11060072\n",
      "0.09487792\n",
      "1.7287996\n",
      "1.1926138\n",
      "0.36620745\n",
      "0.24307564\n",
      "1.2508672\n",
      "0.6575\n",
      "0.79985696\n",
      "1.8905823\n",
      "1.7977755\n",
      "2.5354772\n",
      "0.00085007766\n",
      "1.8597246\n",
      "0.9016621\n",
      "0.33036345\n",
      "1.2111987\n",
      "2.482183\n",
      "0.076850474\n",
      "0.33136436\n",
      "0.39984524\n",
      "1.2927521\n",
      "0.5240664\n",
      "0.20682149\n",
      "1.5926361\n",
      "0.030475918\n",
      "1.2605493\n",
      "1.0665126\n",
      "0.07753423\n",
      "0.07200517\n",
      "2.136651\n",
      "2.2983894\n",
      "1.165624\n",
      "0.02566835\n",
      "0.00041511978\n",
      "0.045999\n",
      "0.29493907\n",
      "0.34644756\n",
      "2.3410954\n",
      "0.70803803\n",
      "0.60662377\n",
      "0.120878845\n",
      "0.91072357\n",
      "0.29460865\n",
      "0.24857111\n",
      "1.2723302\n",
      "0.7850663\n",
      "0.35175902\n",
      "0.12967996\n",
      "1.1070857\n",
      "1.144102\n",
      "0.06589251\n",
      "0.6237088\n",
      "0.34682617\n",
      "1.0217941\n",
      "0.55838263\n",
      "0.9421785\n",
      "1.6075513\n",
      "1.6712974\n",
      "3.045278\n",
      "0.41956598\n",
      "0.4740375\n",
      "0.52872723\n",
      "0.6961269\n",
      "0.10555731\n",
      "2.004897\n",
      "2.0527813\n",
      "1.1765041\n",
      "0.0071082795\n",
      "0.7425325\n",
      "0.25244096\n",
      "1.0160925\n",
      "5.674201e-05\n",
      "0.5385604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1565616\n",
      "0.7680125\n",
      "1.7495142\n"
     ]
    }
   ],
   "source": [
    "os.chdir('path\\\\to\\\\dataset\\\\folder\\\\author\\\\sudesh')\n",
    "cwd=os.getcwd() #getting current working directory as we will be handling huge amoout of datasets.\n",
    "# listing the image file names and counting the number of images.\n",
    "images=os.listdir() \n",
    "num_of_images=len(images) \n",
    "\n",
    "# for every image in the dataset we are executing the below code.\n",
    "\n",
    "for k in range(0,num_of_images):\n",
    "  \n",
    "  #reading the image and prepossing the image such that it can be submitted to the model\n",
    "    \n",
    "  image_raw = tf.io.read_file(cwd+\"\\\\\"+images[k])\n",
    "  image = tf.image.decode_image(image_raw)\n",
    "  image = preprocess(image)\n",
    "\n",
    "  #submitting the image to the model and retreiving the predictions\n",
    "    \n",
    "  image_probs = pretrained_model.predict(image)\n",
    "  _, image_class, class_confidence = get_imagenet_label(image_probs)\n",
    "    \n",
    "  #getting the label of the image.\n",
    "  label_index = get_index(image)\n",
    "  \n",
    "  #   #creating tensorflow object based on label_index such that it can be submitted to create_adversarial_pattern method \n",
    "  #to generate perturbations\n",
    "\n",
    "  label = tf.one_hot(label_index, image_probs.shape[-1])\n",
    "  label = tf.reshape(label, (1, image_probs.shape[-1]))  \n",
    "  perturbations = create_adversarial_pattern(image, label)\n",
    "\n",
    "  #writing the image name to worksheet\n",
    "\n",
    "  Worksheet.write(k+1,0,images[k])\n",
    "    \n",
    "  # array of epsilon values\n",
    "  epsilons = [0, 0.01, 0.1, 0.15]\n",
    "  descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n",
    "                  for eps in epsilons]\n",
    " \n",
    "  for i, eps in enumerate(epsilons):\n",
    "    \n",
    "    #creating adversarial images by combining image with perturbations multiplied by eps\n",
    "    adv_x = image + eps*perturbations\n",
    "    adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
    "    \n",
    "    #collecting the label detected and confidence of perturbated images.\n",
    "    label_detected,confidence = display_images(adv_x, descriptions[i])\n",
    "    Worksheet.write(k+1,i+1,label_detected+'('+str(confidence*100)+')')\n",
    "    #writing it to xls file\n",
    "Workbook.save('Filename.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The stored excel files for differnet models and different datasets are used for creation of graphs represented in Techincal review</b></br></br>\n",
    "<b>The dataset consists of 1500 images downloaded from imageCV</b> <a target=\"_blank\" href=\"https://images.cv\">imagenet</a></br></br>\n",
    "<b>All the models are trained as using imagenet</b> <a target=\"_blank\" href=\"https://image-net.org/\">imagenet</a></br></br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
